{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 02:** Creating your own CNN with PyTorch"
      ],
      "metadata": {
        "id": "kEVufSiWXKCT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **General Instructions**\n",
        "- In this lab, you'll create your own CNN in order to surpass an accuracy of 70% on CIFAR-10.\n",
        "### **System Diagram Requirement**\n",
        "You must include a **diagram of your system pipeline** showing the CNN architecture.\n",
        "\n",
        "This diagram is **required** to understand your model logic.\n",
        "\n",
        "You can draw it digitally, use any Pyhton library, or by hand and include an image.\n",
        "\n",
        "If your diagram was created assisted by GenAI, also include the `promt` used in the next block. If the generated system diagram is not clear or you cannot interpret it, adjust the prompt as needed or draw it by hand.\n"
      ],
      "metadata": {
        "id": "THdWKIPFXc7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*If you used GenAI, write your prompt here..*"
      ],
      "metadata": {
        "id": "xEjNQq2JYIL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Create a technical architecture diagram for a CNN: Input (32x32x3) -> [Conv(3x3, 32) + BatchNorm + ReLU] x2 -> MaxPool(2x2) -> [Conv(3x3, 64) + BatchNorm + ReLU] x2 -> MaxPool(2x2) -> Flatten -> Dropout(0.3) -> FullyConnected(512) -> ReLU -> Dropout(0.3) -> Output(10).\""
      ],
      "metadata": {
        "id": "3qn3zb11YOxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the CIFAR-10 dataset**"
      ],
      "metadata": {
        "id": "_AOX6Y0RYPky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "r2kL_zSRYT3j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create your CNN with PyTorch and train it on the CIFAR-10 dataset**"
      ],
      "metadata": {
        "id": "HVzT4T_IYoA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        # Bloque 1\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        # Bloque 2\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        # Clasificador\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64 * 8 * 8, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "model = CustomCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Ciclo de entrenamiento\n",
        "epochs = 15\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss/len(trainloader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLF0etVsYooK",
        "outputId": "e50538b0-abf4-4477-8b7f-924439953ed5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 - Loss: 1.4384\n",
            "Epoch 2/15 - Loss: 1.0556\n",
            "Epoch 3/15 - Loss: 0.9065\n",
            "Epoch 4/15 - Loss: 0.8284\n",
            "Epoch 5/15 - Loss: 0.7745\n",
            "Epoch 6/15 - Loss: 0.7332\n",
            "Epoch 7/15 - Loss: 0.7008\n",
            "Epoch 8/15 - Loss: 0.6745\n",
            "Epoch 9/15 - Loss: 0.6550\n",
            "Epoch 10/15 - Loss: 0.6318\n",
            "Epoch 11/15 - Loss: 0.6121\n",
            "Epoch 12/15 - Loss: 0.5921\n",
            "Epoch 13/15 - Loss: 0.5755\n",
            "Epoch 14/15 - Loss: 0.5643\n",
            "Epoch 15/15 - Loss: 0.5519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluate the accuracy of your CNN (must be >= 70%)**"
      ],
      "metadata": {
        "id": "VERubbrvYsFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Final Accuracy on CIFAR-10: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcB4TZsFY7Jk",
        "outputId": "8fd9a766-e9f9-446a-81b9-3238fa731c41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy on CIFAR-10: 81.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **System Diagram**\n",
        "\n",
        "Insert your system diagram below (image or drawing). It must clearly show:\n",
        "\n",
        "- Number of convolutional layers\n",
        "\n",
        "- Kernel size(s)\n",
        "\n",
        "- Pooling layers (if any)  \n",
        "\n",
        "- etc..  "
      ],
      "metadata": {
        "id": "LxrLP75jZBc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Insert or display your system diagram image here"
      ],
      "metadata": {
        "id": "gOqZBJBKZWYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Written Analysis Questions**\n",
        "\n"
      ],
      "metadata": {
        "id": "4Exss1PEZiQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Why increasing depth could improve performance.**\n",
        "\n",
        "Increasing the depth of a network allows it to learn a hierarchy of features. Initial layers detect simple patterns like edges and colors, while deeper layers can combine these to recognize more complex and abstract shapes (like eyes, wheels, or specific textures), leading to better representation of the data.\n",
        "\n",
        "**2. Under what conditions deeper networks may hurt performance.**\n",
        "\n",
        "Deeper networks can suffer from the vanishing gradient problem, where the error signal becomes too small to update the early layers. Additionally, if the model has too many parameters relative to the amount of training data, it can lead to overfitting, where the network memorizes the training set instead of learning to generalize.\n",
        "\n",
        "**3. How could dropout, batch normalization, or data augmentation help?**\n",
        "\n",
        "- Dropout: Randomly deactivates neurons during training, which prevents the network from becoming overly dependent on specific connections and reduces overfitting.\n",
        "\n",
        "- Batch Normalization: Normalizes the activations of each layer, which stabilizes and accelerates the training process, allowing for higher learning rates.\n",
        "\n",
        "- Data Augmentation: Artificially increases the size of the dataset by creating modified versions of images (rotations, flips), helping the model become invariant to these changes and improve generalization.\n",
        "\n",
        "**4. How would you determine whether your CNN is overfitting or underfitting?**\n",
        "\n",
        "By monitoring the training vs. validation loss/accuracy. If the training accuracy is much higher than the validation accuracy (and the validation loss starts to increase), the model is overfitting. If both training and validation accuracies remain low and plateau early, the model is underfitting.\n",
        "\n",
        "**5. Which architectural components most impact computational cost?**\n",
        "\n",
        "The convolutional layers are the most computationally expensive due to the high number of matrix multiplications (FLOPs) required. However, the first fully connected (Linear) layer after flattening usually contains the highest number of trainable parameters, impacting memory usage.\n",
        "\n",
        "**6. Whether the accuracy gain justifies the added complexity in a real-world deployment scenario.**\n",
        "\n",
        "This depends on the use case. In critical systems (like medical diagnosis or autonomous driving), even a 1% gain in accuracy is crucial and justifies the complexity. In real-time mobile applications, a lighter model (like MobileNet) might be preferred to ensure low latency and battery efficiency, even if it is slightly less accurate."
      ],
      "metadata": {
        "id": "Op_HA0c8ZoaZ"
      }
    }
  ]
}